# FailGuard AI - Predictive Software Failure Detection System

An AI-driven predictive analytics system that identifies software modules with a high probability of failure before deployment using machine learning on historical software metrics.

## ğŸ¯ Project Overview

FailGuard AI helps development teams:
- **Predict** which software modules are at high risk of failure
- **Prioritize** code reviews and testing efforts
- **Reduce** testing costs and time-to-market
- **Improve** release quality and reliability
- **Perform** risk-based debugging and resource allocation

## ğŸ“Š Input Features

The system analyzes 8 key software metrics:

- **LOC** â€“ Lines of Code (module size)
- **WMC** â€“ Weighted Methods per Class (complexity)
- **RFC** â€“ Response for a Class (method dependencies)
- **CBO** â€“ Coupling Between Objects (interdependencies)
- **LCOM** â€“ Lack of Cohesion (method-attribute relationships)
- **Code Churn** â€“ Recent code changes
- **Number of Developers** â€“ Developer count for the module
- **Past Defects** â€“ Historical defect count

## ğŸ“ Output

For each analyzed module, the system provides:

1. **Risk Level**: LOW / MEDIUM / HIGH
2. **Failure Probability**: Percentage (0-100%)
3. **Model Confidence**: Prediction confidence score
4. **Actionable Recommendations**: Based on risk level

## ğŸ—ï¸ Architecture

### Components

```
FailGuard AI/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ nasa_promise.csv          # Original dataset
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ cleaned_data.csv          # Preprocessed data
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ train_model.py                # Model training pipeline
â”‚   â”œâ”€â”€ predict.py                    # Inference engine
â”‚   â”œâ”€â”€ failguard_model.joblib        # Trained model (generated)
â”‚   â””â”€â”€ scaler.joblib                 # Feature scaler (generated)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py          # Data cleaning & normalization
â”‚   â”œâ”€â”€ feature_engineering.py         # Feature creation
â”‚   â”œâ”€â”€ evaluation.py                  # Model evaluation metrics
â”‚   â””â”€â”€ utils.py                       # Helper utilities
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html                    # Main input form
â”‚   â”œâ”€â”€ dashboard.html                # Visualization dashboard
â”‚   â””â”€â”€ result.html                   # Prediction results
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/styles.css               # Styling
â”‚   â””â”€â”€ js/main.js                    # Client-side logic
â”œâ”€â”€ app.py                            # Flask web application
â”œâ”€â”€ config.py                         # Configuration settings
â”œâ”€â”€ requirements.txt                  # Python dependencies
â””â”€â”€ README.md                         # This file
```

### Machine Learning Pipeline

```
Raw Data (NASA PROMISE)
    â†“
Data Preprocessing (cleaning, normalization)
    â†“
Feature Engineering (selection, scaling)
    â†“
Model Training (4 algorithms)
    â”œâ”€â”€ Logistic Regression
    â”œâ”€â”€ Random Forest â­ (Best Performer)
    â”œâ”€â”€ XGBoost
    â””â”€â”€ Support Vector Machine
    â†“
Model Evaluation (Accuracy, Precision, Recall, F1, ROC-AUC)
    â†“
Model Serialization (saved to joblib)
    â†“
Flask API + Web UI (Real-time predictions)
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Prepare Data

Ensure `data/raw/nasa_promise.csv` contains your dataset with columns for:
- Software metrics (loc, wmc, rfc, cbo, lcom, etc.)
- Target variable (defects or buggy flag)

### 3. Train Models

```bash
python models/train_model.py
```

This will:
- Load and preprocess the NASA PROMISE dataset
- Train 4 different models
- Evaluate all models
- Save the best model (Random Forest)
- Generate scaler for feature normalization

**Output**: 
- `models/failguard_model.joblib` â€“ Trained model
- `models/scaler.joblib` â€“ Feature scaler
- `data/processed/cleaned_data.csv` â€“ Processed training data

### 4. Run Flask Application

```bash
python app.py
```

The Flask server will start at `http://localhost:5000`

### 5. Access Web UI

Open your browser and navigate to:
```
http://localhost:5000
```

## ğŸ® Usage

### Via Web UI

1. Go to home page (`/`)
2. Enter software module metrics in the form
3. Click "Analyze Module Risk"
4. View prediction results with recommendations

### Via API

**Endpoint**: `POST /api/predict`

**Request**:
```bash
curl -X POST http://localhost:5000/api/predict \
  -H "Content-Type: application/json" \
  -d '{
    "loc": 500,
    "wmc": 15,
    "rfc": 20,
    "cbo": 8,
    "lcom": 0.5,
    "code_churn": 10,
    "num_developers": 3,
    "past_defects": 2
  }'
```

**Response**:
```json
{
  "success": true,
  "probability": 42.5,
  "risk_level": "MEDIUM",
  "risk_color": "#ffc107",
  "confidence": 75.3,
  "prediction": "DEFECTIVE"
}
```

## ğŸ“ˆ Model Performance

The system evaluates models using:

- **Accuracy**: Overall correctness
- **Precision**: True positives / All positives (minimize false alarms)
- **Recall**: True positives / All true cases (catch real defects)
- **F1-Score**: Harmonic mean of precision and recall
- **ROC-AUC**: Area under the receiver operating characteristic curve

The **Random Forest** model typically achieves the best balance of metrics.

## âš™ï¸ Configuration

Edit `config.py` to customize:

```python
# Data paths
DATA_RAW_PATH = "data/raw/nasa_promise.csv"
DATA_PROCESSED_PATH = "data/processed/cleaned_data.csv"

# Feature names (in order)
FEATURE_NAMES = ['loc', 'wmc', 'rfc', 'cbo', 'lcom', 'code_churn', 'num_developers', 'past_defects']

# Risk thresholds
RISK_THRESHOLDS = {
    'LOW': 0.33,      # < 33% probability
    'MEDIUM': 0.67,   # 33-67%
    'HIGH': 1.0       # > 67%
}

# Flask settings
DEBUG = True
SECRET_KEY = 'your-secret-key'
```

## ğŸ“š Project Structure Details

### `models/train_model.py`
- Loads NASA PROMISE dataset
- Trains 4 ML algorithms
- Evaluates and compares models
- Saves best model with joblib

### `models/predict.py`
- `FailGuardPredictor` class for making predictions
- Loads trained model and scaler
- Handles feature normalization
- Returns formatted prediction results

### `src/data_preprocessing.py`
- Data loading and cleaning
- Missing value handling
- Feature normalization (StandardScaler)
- Train/test split (80/20)

### `src/evaluation.py`
- Comprehensive metrics calculation
- Confusion matrix generation
- Classification reports
- Feature importance extraction

### `app.py`
- Flask web application
- REST API endpoints
- Static file serving
- Error handling

## ğŸŒ Web Pages

### `/` â€“ Home Page (Input Form)
- Interactive form for entering software metrics
- Tooltips for metric explanations
- Real-time form validation
- Results display section

### `/dashboard` â€“ Analytics Dashboard
- Model performance metrics
- Risk distribution visualization
- Quick test functionality
- Feature importance (when available)

### `/result` â€“ Detailed Results
- Risk level with visual indicator
- Failure probability with progress bar
- Input metrics summary
- Actionable recommendations

## ğŸ”„ ML Models Included

1. **Logistic Regression** â€“ Fast, interpretable baseline
2. **Random Forest** â€“ Ensemble method, best performer â­
3. **XGBoost** â€“ Gradient boosting, high accuracy
4. **Support Vector Machine** â€“ Kernel-based, good for complex patterns

## ğŸ› ï¸ Development & Customization

### Add New Features

Edit `FEATURE_NAMES` in `config.py` and modify preprocessing accordingly.

### Change Risk Thresholds

Adjust `RISK_THRESHOLDS` in `config.py`:
```python
RISK_THRESHOLDS = {
    'LOW': 0.25,    # Stricter
    'MEDIUM': 0.75,
    'HIGH': 1.0
}
```

### Retrain with New Data

1. Update `data/raw/nasa_promise.csv`
2. Run `python models/train_model.py`
3. Flask will automatically use the new model

### Customize UI

- Modify `templates/*.html` for layout
- Edit `static/css/styles.css` for styling
- Update `static/js/main.js` for behavior

## ğŸ“ API Reference

### GET `/` 
Returns the home page with input form.

### GET `/dashboard`
Returns the analytics dashboard.

### POST `/api/predict`
Makes a prediction based on input metrics.

**Parameters** (JSON):
- `loc` (float): Lines of Code
- `wmc` (float): Weighted Methods per Class
- `rfc` (float): Response for a Class
- `cbo` (float): Coupling Between Objects
- `lcom` (float): Lack of Cohesion (0-1)
- `code_churn` (float): Code changes
- `num_developers` (int): Developer count
- `past_defects` (int): Historical defects

### GET `/api/features`
Returns list of required features and descriptions.

### GET `/api/health`
Health check endpoint (returns model status).

## ğŸ› Troubleshooting

**Model not found error**
- Run `python models/train_model.py` first to train the model

**Port 5000 already in use**
- Change in `app.py`: `app.run(port=5001)`

**Import errors**
- Ensure all packages from `requirements.txt` are installed
- Verify Python 3.8+ is being used

**Data file not found**
- Ensure `data/raw/nasa_promise.csv` exists with proper columns
- Check file path and column naming

## ğŸ“ Technical Stack

- **Python 3.8+**
- **scikit-learn** â€“ ML algorithms
- **XGBoost** â€“ Gradient boosting
- **Flask** â€“ Web framework
- **Pandas** â€“ Data processing
- **NumPy** â€“ Numerical operations
- **Plotly** â€“ Interactive visualizations

## ğŸ“Š Dataset

The system is trained on the **NASA PROMISE dataset**, which contains:
- Software module metrics from real projects
- Defect histories
- Multiple programming languages and project types

Source: http://promise.site.uottawa.ca/

## ğŸ¤ Contributing

To improve the system:

1. Add more models in `models/train_model.py`
2. Enhance feature engineering in `src/feature_engineering.py`
3. Improve UI in `templates/` and `static/`
4. Add more evaluation metrics in `src/evaluation.py`

## ğŸ“„ License

This project is provided as-is for educational and commercial use.

## ğŸ™ Acknowledgments

- NASA PROMISE dataset contributors
- scikit-learn and XGBoost communities
- Flask development team

## ğŸ“ Support

For issues or questions:
1. Check configuration in `config.py`
2. Review logs from Flask output
3. Ensure all dependencies are installed
4. Verify dataset format matches expected columns

---

**FailGuard AI** - Predict and prevent software failures before they reach production. ğŸ›¡ï¸
